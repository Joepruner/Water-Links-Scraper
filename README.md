# Water-Links-Scraper

<p>Water-Links-Scraper is a web crawler designed to start from a root web page, 
retreive all the hyperlinks, and analyze which links are more related to content 
regarding water quality, and related water quality topics. It will then </p>

<h3> Installing Scrapy </h3>
<p>Scrapy requires Python 2.7 or Python 3.4 and above to run.</p>
If you're using Anaconda or Miniconda, scrapy can be installed with the command:</br>
<b>$: conda install -c conda-forge scrapy</b><br  /><br  />

<p>Scrapy can also be installed using pip:<br  />
<b>$: pip install scrapy</b></p>
<p>Please check the
<a href="https://docs.scrapy.org/en/latest/intro/install.html#intro-install-platform-notes">
operating system specific guide</a> for more installation details.</p>

<p>It is highly reccomended to install Scrapy <a href="https://virtualenv.pypa.io/en/stable/installation/">
within a virtual environment</a>,
so that Scrapy Python packages do not conflict with any already-installed Python system 
packages</p>

<p>Clone this repository into your virtual environment, and make sure it is activated
by running the command:</p>
</p><b>$: source ~virtual_workspace/bin/activate</b></p>
